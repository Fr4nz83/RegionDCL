{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137f947c-08ec-4031-84d5-97cb96337d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data_util.dataset import CityData\n",
    "from model.regiondcl import PatternEncoder, RegionEncoder\n",
    "from model.trainer import PatternTrainer, RegionTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db24b40-9074-494c-8132-c5392be8f485",
   "metadata": {},
   "source": [
    "#### Arguments used by subsequent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f05197-83b3-457c-b87f-605067bc0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "\n",
    "args.city = \"Paris\"\n",
    "args.no_random = False\n",
    "args.fixed = False\n",
    "args.dim = 64\n",
    "args.d_feedforward = 1024\n",
    "args.building_head = 8\n",
    "args.building_layers = 2\n",
    "args.building_dropout = 0.2\n",
    "args.building_activation = 'relu'\n",
    "args.bottleneck_head = 8\n",
    "args.bottleneck_layers = 2\n",
    "args.bottleneck_dropout = 0.2\n",
    "args.bottleneck_activation = 'relu'\n",
    "args.lr=0.0001\n",
    "args.weight_decay=0.0001\n",
    "args.gamma=0.999\n",
    "args.save_name='pattern_embedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda871e-7d6f-484d-8309-f3a1e1f65428",
   "metadata": {},
   "source": [
    "#### Pattern training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a870c41-3cb0-42c1-9599-d179c39efcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = CityData(args.city, with_random=not args.no_random)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bc8853-93c3-4446-91b9-96848bab50d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francescolettich/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.87it/s, loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: InfoNCE Loss 2.8697494361135694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:23<00:00,  1.90it/s, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: InfoNCE Loss 1.6125569873385959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.87it/s, loss=0.501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: InfoNCE Loss 1.1375351442231072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.87it/s, loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: InfoNCE Loss 0.915105895863639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:23<00:00,  1.89it/s, loss=0.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: InfoNCE Loss 0.7960723929935032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.84it/s, loss=0.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: InfoNCE Loss 0.6854121244615978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.85it/s, loss=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: InfoNCE Loss 0.6158585439125697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.85it/s, loss=0.382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: InfoNCE Loss 0.5474309768941668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.87it/s, loss=0.0584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: InfoNCE Loss 0.4918755794564883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:24<00:00,  1.84it/s, loss=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: InfoNCE Loss 0.4511387017038133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:20<00:00,  2.15it/s, loss=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: InfoNCE Loss 0.32333849171797435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.11it/s, loss=0.066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: InfoNCE Loss 0.3384299533234702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.07it/s, loss=0.0618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: InfoNCE Loss 0.290262867593103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.12it/s, loss=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: InfoNCE Loss 0.28456874423556855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.08it/s, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: InfoNCE Loss 0.2683285292651918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.08it/s, loss=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: InfoNCE Loss 0.27664744953314463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.13it/s, loss=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: InfoNCE Loss 0.23765787109732628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.10it/s, loss=0.338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: InfoNCE Loss 0.24812058607737222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.10it/s, loss=0.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: InfoNCE Loss 0.22100412083996668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|███████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.10it/s, loss=0.00721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: InfoNCE Loss 0.2244450529002481\n",
      "Pattern (building groups) training finished. Embeddings have been saved in embeddings/ directory.\n"
     ]
    }
   ],
   "source": [
    "pattern_encoder = PatternEncoder(d_building=city_data.building_feature_dim,\n",
    "                                 d_poi=city_data.poi_feature_dim,\n",
    "                                 d_hidden=args.dim,\n",
    "                                 d_feedforward=args.d_feedforward,\n",
    "                                 building_head=args.building_head,\n",
    "                                 building_layers=args.building_layers,\n",
    "                                 building_dropout=args.building_dropout,\n",
    "                                 building_distance_penalty=1,\n",
    "                                 building_activation=args.building_activation,\n",
    "                                 bottleneck_head=args.bottleneck_head,\n",
    "                                 bottleneck_layers=args.bottleneck_layers,\n",
    "                                 bottleneck_dropout=args.bottleneck_dropout,\n",
    "                                 bottleneck_activation=args.bottleneck_activation).to(device)\n",
    "\n",
    "# Encode building patterns.\n",
    "pattern_optimizer = torch.optim.Adam(pattern_encoder.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "pattern_scheduler = torch.optim.lr_scheduler.StepLR(pattern_optimizer, step_size=1, gamma=args.gamma)\n",
    "pattern_trainer = PatternTrainer(city_data, pattern_encoder, pattern_optimizer, pattern_scheduler)\n",
    "pattern_trainer.train_pattern_contrastive(epochs=20, save_name=args.save_name)\n",
    "print('Pattern (building groups) training finished. Embeddings have been saved in embeddings/ directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9f1bc3-e4c2-4ee3-896c-fbe7808097b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pretraining dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francescolettich/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 118.02it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Tiplet Loss: 5.733050794211048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 111.11it/s, loss=7.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Tiplet Loss: 4.783924699122548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 120.85it/s, loss=18.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Tiplet Loss: 6.123286394553942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 119.09it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Tiplet Loss: 4.719038029720909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 113.56it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Tiplet Loss: 4.11406084477755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 121.19it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Tiplet Loss: 6.042075970089742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 117.27it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Tiplet Loss: 4.057916764487997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 112.99it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Tiplet Loss: 3.83761165534542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 120.02it/s, loss=17.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Tiplet Loss: 5.895370361291846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 116.94it/s, loss=16.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Tiplet Loss: 4.455195023720725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 112.80it/s, loss=17.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Tiplet Loss: 3.3467080013172046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 119.68it/s, loss=4.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Tiplet Loss: 5.868094685128895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 116.53it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Tiplet Loss: 3.7715611318398636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 112.17it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Tiplet Loss: 3.745418799304259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 119.80it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Tiplet Loss: 5.485282574459128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 115.34it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Tiplet Loss: 3.596848978633769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 112.85it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Tiplet Loss: 3.21716950625108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|████████████████████████████████████████████████████████████| 2839/2839 [00:23<00:00, 121.51it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Tiplet Loss: 5.502993434951019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████████████████████████████████████████| 855/855 [00:07<00:00, 118.58it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Tiplet Loss: 3.892980766296387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████████████████████████████████████████████████████████| 407/407 [00:03<00:00, 113.86it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Tiplet Loss: 2.558074777776545\n",
      "Training finished. Region embeddings have been saved in embeddings/ directory.\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(f'embeddings/{args.city}/{args.save_name}_20.npy')\n",
    "region_aggregator = RegionEncoder(d_hidden=args.dim, d_head=8)\n",
    "region_aggregator.to(device)\n",
    "region_optimizer = torch.optim.Adam(region_aggregator.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "region_scheduler = torch.optim.lr_scheduler.StepLR(region_optimizer, step_size=1, gamma=args.gamma)\n",
    "region_trainer = RegionTrainer(city_data, \n",
    "                               pattern_encoder, \n",
    "                               pattern_optimizer, \n",
    "                               pattern_scheduler, \n",
    "                               region_aggregator,\n",
    "                               region_optimizer, \n",
    "                               region_scheduler)\n",
    "\n",
    "region_trainer.train_region_triplet_freeze(epochs=20, \n",
    "                                           embeddings=embeddings,\n",
    "                                           adaptive=not args.fixed,\n",
    "                                           save_name='RegionDCL_',\n",
    "                                           window_sizes=[1000, 2000, 3000])\n",
    "\n",
    "print('Training finished. Region embeddings have been saved in embeddings/ directory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b8b9f-7b67-4ff7-8889-3ea0824333b5",
   "metadata": {},
   "source": [
    "#### Fondere i region embedding prodotti da RegionDCL con le celle IRIS di Parigi. Gli indici degli embedding dovrebbero essere uguali agli indici in region_downstream.pkl, il quale contiene come regioni le celle IRIS di Parigi. A sua volta, questo e' stato creato dal dataframe originario contenente le celle IRIS di Parigi. Ci dovrebbe quindi essere una corrispondenza 1-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb95612c-94bc-4f4f-b6bf-abef34ac3b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.541241</td>\n",
       "      <td>-1.552484</td>\n",
       "      <td>0.356977</td>\n",
       "      <td>-1.736598</td>\n",
       "      <td>0.142796</td>\n",
       "      <td>-1.446629</td>\n",
       "      <td>1.474845</td>\n",
       "      <td>1.793473</td>\n",
       "      <td>-2.367339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648237</td>\n",
       "      <td>-0.885627</td>\n",
       "      <td>-0.937770</td>\n",
       "      <td>0.419687</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>-1.014766</td>\n",
       "      <td>-1.895285</td>\n",
       "      <td>-0.646993</td>\n",
       "      <td>-1.090850</td>\n",
       "      <td>-0.565864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.347954</td>\n",
       "      <td>0.650689</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.584189</td>\n",
       "      <td>-0.199877</td>\n",
       "      <td>-0.448162</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>-0.175236</td>\n",
       "      <td>-0.107955</td>\n",
       "      <td>-1.175052</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211076</td>\n",
       "      <td>-0.181422</td>\n",
       "      <td>-0.476251</td>\n",
       "      <td>0.415405</td>\n",
       "      <td>-1.052445</td>\n",
       "      <td>-0.799308</td>\n",
       "      <td>-1.164737</td>\n",
       "      <td>-0.697996</td>\n",
       "      <td>0.541870</td>\n",
       "      <td>-1.378236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.698959</td>\n",
       "      <td>0.896405</td>\n",
       "      <td>-0.875261</td>\n",
       "      <td>0.391883</td>\n",
       "      <td>-1.496848</td>\n",
       "      <td>-0.138475</td>\n",
       "      <td>-1.719965</td>\n",
       "      <td>2.227425</td>\n",
       "      <td>1.232168</td>\n",
       "      <td>-2.249786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267723</td>\n",
       "      <td>-0.522346</td>\n",
       "      <td>-0.962249</td>\n",
       "      <td>-0.219073</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>-0.248601</td>\n",
       "      <td>-1.354952</td>\n",
       "      <td>-0.742301</td>\n",
       "      <td>-1.021840</td>\n",
       "      <td>-0.666556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.157673</td>\n",
       "      <td>-0.647407</td>\n",
       "      <td>0.808782</td>\n",
       "      <td>-1.313741</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>-1.547369</td>\n",
       "      <td>1.824086</td>\n",
       "      <td>-0.395828</td>\n",
       "      <td>-1.862130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>-0.098627</td>\n",
       "      <td>-1.785979</td>\n",
       "      <td>-0.718676</td>\n",
       "      <td>1.533811</td>\n",
       "      <td>1.153300</td>\n",
       "      <td>-1.099394</td>\n",
       "      <td>-1.633024</td>\n",
       "      <td>-1.415450</td>\n",
       "      <td>-0.753298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005342</td>\n",
       "      <td>-0.128149</td>\n",
       "      <td>-0.995483</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>2.689951</td>\n",
       "      <td>0.246803</td>\n",
       "      <td>1.487742</td>\n",
       "      <td>-0.738581</td>\n",
       "      <td>-1.134661</td>\n",
       "      <td>1.549973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820444</td>\n",
       "      <td>-1.813761</td>\n",
       "      <td>0.059071</td>\n",
       "      <td>1.641847</td>\n",
       "      <td>-0.746659</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.840271</td>\n",
       "      <td>0.899284</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.633954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>1.210889</td>\n",
       "      <td>0.605233</td>\n",
       "      <td>-1.254536</td>\n",
       "      <td>0.798792</td>\n",
       "      <td>0.989185</td>\n",
       "      <td>-0.442684</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>0.460976</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575556</td>\n",
       "      <td>-1.725776</td>\n",
       "      <td>0.078569</td>\n",
       "      <td>1.030678</td>\n",
       "      <td>-1.569415</td>\n",
       "      <td>-1.628996</td>\n",
       "      <td>-1.663372</td>\n",
       "      <td>0.147831</td>\n",
       "      <td>1.101275</td>\n",
       "      <td>-0.090091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>-1.607422</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.211732</td>\n",
       "      <td>-0.428983</td>\n",
       "      <td>0.278820</td>\n",
       "      <td>-0.859638</td>\n",
       "      <td>-0.237076</td>\n",
       "      <td>-0.339976</td>\n",
       "      <td>1.102264</td>\n",
       "      <td>-0.078230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385881</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>-0.366797</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.139275</td>\n",
       "      <td>1.037128</td>\n",
       "      <td>1.401160</td>\n",
       "      <td>0.522745</td>\n",
       "      <td>0.776658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>-0.751333</td>\n",
       "      <td>-0.615479</td>\n",
       "      <td>-0.774459</td>\n",
       "      <td>0.817685</td>\n",
       "      <td>1.344045</td>\n",
       "      <td>0.490856</td>\n",
       "      <td>0.643572</td>\n",
       "      <td>-1.366485</td>\n",
       "      <td>1.052982</td>\n",
       "      <td>0.755563</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.642248</td>\n",
       "      <td>-0.590999</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>1.085998</td>\n",
       "      <td>0.402556</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>-0.463104</td>\n",
       "      <td>1.657594</td>\n",
       "      <td>0.099996</td>\n",
       "      <td>1.220423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>0.663056</td>\n",
       "      <td>1.437725</td>\n",
       "      <td>-1.110954</td>\n",
       "      <td>0.309514</td>\n",
       "      <td>-1.054076</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>-0.728029</td>\n",
       "      <td>1.393851</td>\n",
       "      <td>1.159602</td>\n",
       "      <td>-1.543969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>-1.011022</td>\n",
       "      <td>-0.575822</td>\n",
       "      <td>0.730162</td>\n",
       "      <td>-0.843872</td>\n",
       "      <td>-1.535553</td>\n",
       "      <td>-1.454355</td>\n",
       "      <td>-0.509752</td>\n",
       "      <td>-0.044040</td>\n",
       "      <td>-1.091046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>-0.592533</td>\n",
       "      <td>1.817990</td>\n",
       "      <td>-0.921036</td>\n",
       "      <td>-0.873506</td>\n",
       "      <td>-0.964541</td>\n",
       "      <td>-1.615351</td>\n",
       "      <td>-0.919549</td>\n",
       "      <td>1.814635</td>\n",
       "      <td>1.499758</td>\n",
       "      <td>-1.614815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606562</td>\n",
       "      <td>-0.173824</td>\n",
       "      <td>0.138459</td>\n",
       "      <td>0.460980</td>\n",
       "      <td>-0.797815</td>\n",
       "      <td>-1.443073</td>\n",
       "      <td>-0.162968</td>\n",
       "      <td>-0.022675</td>\n",
       "      <td>0.516509</td>\n",
       "      <td>-0.519815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2841 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.155640  0.541241 -1.552484  0.356977 -1.736598  0.142796 -1.446629   \n",
       "1     1.347954  0.650689  0.018240  0.584189 -0.199877 -0.448162  0.299191   \n",
       "2    -0.698959  0.896405 -0.875261  0.391883 -1.496848 -0.138475 -1.719965   \n",
       "3    -0.209782 -0.157673 -0.647407  0.808782 -1.313741  1.138889 -1.547369   \n",
       "4    -0.005342 -0.128149 -0.995483  0.154544  2.689951  0.246803  1.487742   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2836  1.210889  0.605233 -1.254536  0.798792  0.989185 -0.442684  0.615255   \n",
       "2837 -1.607422  0.560672  0.211732 -0.428983  0.278820 -0.859638 -0.237076   \n",
       "2838 -0.751333 -0.615479 -0.774459  0.817685  1.344045  0.490856  0.643572   \n",
       "2839  0.663056  1.437725 -1.110954  0.309514 -1.054076 -1.031078 -0.728029   \n",
       "2840 -0.592533  1.817990 -0.921036 -0.873506 -0.964541 -1.615351 -0.919549   \n",
       "\n",
       "            7         8         9   ...        54        55        56  \\\n",
       "0     1.474845  1.793473 -2.367339  ... -0.648237 -0.885627 -0.937770   \n",
       "1    -0.175236 -0.107955 -1.175052  ...  1.211076 -0.181422 -0.476251   \n",
       "2     2.227425  1.232168 -2.249786  ... -0.267723 -0.522346 -0.962249   \n",
       "3     1.824086 -0.395828 -1.862130  ...  0.210744 -0.098627 -1.785979   \n",
       "4    -0.738581 -1.134661  1.549973  ... -0.820444 -1.813761  0.059071   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2836 -0.004198  0.460976  0.040388  ... -0.575556 -1.725776  0.078569   \n",
       "2837 -0.339976  1.102264 -0.078230  ... -0.385881  0.997247  0.881965   \n",
       "2838 -1.366485  1.052982  0.755563  ... -1.642248 -0.590999  0.291287   \n",
       "2839  1.393851  1.159602 -1.543969  ...  0.632038 -1.011022 -0.575822   \n",
       "2840  1.814635  1.499758 -1.614815  ...  0.606562 -0.173824  0.138459   \n",
       "\n",
       "            57        58        59        60        61        62        63  \n",
       "0     0.419687  0.025002 -1.014766 -1.895285 -0.646993 -1.090850 -0.565864  \n",
       "1     0.415405 -1.052445 -0.799308 -1.164737 -0.697996  0.541870 -1.378236  \n",
       "2    -0.219073  0.724396 -0.248601 -1.354952 -0.742301 -1.021840 -0.666556  \n",
       "3    -0.718676  1.533811  1.153300 -1.099394 -1.633024 -1.415450 -0.753298  \n",
       "4     1.641847 -0.746659 -0.228584 -0.840271  0.899284  0.710280  0.633954  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2836  1.030678 -1.569415 -1.628996 -1.663372  0.147831  1.101275 -0.090091  \n",
       "2837 -0.366797  0.009761  0.139275  1.037128  1.401160  0.522745  0.776658  \n",
       "2838  1.085998  0.402556  0.020732 -0.463104  1.657594  0.099996  1.220423  \n",
       "2839  0.730162 -0.843872 -1.535553 -1.454355 -0.509752 -0.044040 -1.091046  \n",
       "2840  0.460980 -0.797815 -1.443073 -0.162968 -0.022675  0.516509 -0.519815  \n",
       "\n",
       "[2841 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_iris</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920440109</th>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.541241</td>\n",
       "      <td>-1.552484</td>\n",
       "      <td>0.356977</td>\n",
       "      <td>-1.736598</td>\n",
       "      <td>0.142796</td>\n",
       "      <td>-1.446629</td>\n",
       "      <td>1.474845</td>\n",
       "      <td>1.793473</td>\n",
       "      <td>-2.367339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648237</td>\n",
       "      <td>-0.885627</td>\n",
       "      <td>-0.937770</td>\n",
       "      <td>0.419687</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>-1.014766</td>\n",
       "      <td>-1.895285</td>\n",
       "      <td>-0.646993</td>\n",
       "      <td>-1.090850</td>\n",
       "      <td>-0.565864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930270105</th>\n",
       "      <td>1.347954</td>\n",
       "      <td>0.650689</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.584189</td>\n",
       "      <td>-0.199877</td>\n",
       "      <td>-0.448162</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>-0.175236</td>\n",
       "      <td>-0.107955</td>\n",
       "      <td>-1.175052</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211076</td>\n",
       "      <td>-0.181422</td>\n",
       "      <td>-0.476251</td>\n",
       "      <td>0.415405</td>\n",
       "      <td>-1.052445</td>\n",
       "      <td>-0.799308</td>\n",
       "      <td>-1.164737</td>\n",
       "      <td>-0.697996</td>\n",
       "      <td>0.541870</td>\n",
       "      <td>-1.378236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751197316</th>\n",
       "      <td>-0.698959</td>\n",
       "      <td>0.896405</td>\n",
       "      <td>-0.875261</td>\n",
       "      <td>0.391883</td>\n",
       "      <td>-1.496848</td>\n",
       "      <td>-0.138475</td>\n",
       "      <td>-1.719965</td>\n",
       "      <td>2.227425</td>\n",
       "      <td>1.232168</td>\n",
       "      <td>-2.249786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267723</td>\n",
       "      <td>-0.522346</td>\n",
       "      <td>-0.962249</td>\n",
       "      <td>-0.219073</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>-0.248601</td>\n",
       "      <td>-1.354952</td>\n",
       "      <td>-0.742301</td>\n",
       "      <td>-1.021840</td>\n",
       "      <td>-0.666556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751176716</th>\n",
       "      <td>-0.209782</td>\n",
       "      <td>-0.157673</td>\n",
       "      <td>-0.647407</td>\n",
       "      <td>0.808782</td>\n",
       "      <td>-1.313741</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>-1.547369</td>\n",
       "      <td>1.824086</td>\n",
       "      <td>-0.395828</td>\n",
       "      <td>-1.862130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>-0.098627</td>\n",
       "      <td>-1.785979</td>\n",
       "      <td>-0.718676</td>\n",
       "      <td>1.533811</td>\n",
       "      <td>1.153300</td>\n",
       "      <td>-1.099394</td>\n",
       "      <td>-1.633024</td>\n",
       "      <td>-1.415450</td>\n",
       "      <td>-0.753298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920020104</th>\n",
       "      <td>-0.005342</td>\n",
       "      <td>-0.128149</td>\n",
       "      <td>-0.995483</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>2.689951</td>\n",
       "      <td>0.246803</td>\n",
       "      <td>1.487742</td>\n",
       "      <td>-0.738581</td>\n",
       "      <td>-1.134661</td>\n",
       "      <td>1.549973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820444</td>\n",
       "      <td>-1.813761</td>\n",
       "      <td>0.059071</td>\n",
       "      <td>1.641847</td>\n",
       "      <td>-0.746659</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.840271</td>\n",
       "      <td>0.899284</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.633954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920070111</th>\n",
       "      <td>1.210889</td>\n",
       "      <td>0.605233</td>\n",
       "      <td>-1.254536</td>\n",
       "      <td>0.798792</td>\n",
       "      <td>0.989185</td>\n",
       "      <td>-0.442684</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>0.460976</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575556</td>\n",
       "      <td>-1.725776</td>\n",
       "      <td>0.078569</td>\n",
       "      <td>1.030678</td>\n",
       "      <td>-1.569415</td>\n",
       "      <td>-1.628996</td>\n",
       "      <td>-1.663372</td>\n",
       "      <td>0.147831</td>\n",
       "      <td>1.101275</td>\n",
       "      <td>-0.090091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930050101</th>\n",
       "      <td>-1.607422</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.211732</td>\n",
       "      <td>-0.428983</td>\n",
       "      <td>0.278820</td>\n",
       "      <td>-0.859638</td>\n",
       "      <td>-0.237076</td>\n",
       "      <td>-0.339976</td>\n",
       "      <td>1.102264</td>\n",
       "      <td>-0.078230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385881</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>-0.366797</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.139275</td>\n",
       "      <td>1.037128</td>\n",
       "      <td>1.401160</td>\n",
       "      <td>0.522745</td>\n",
       "      <td>0.776658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910270114</th>\n",
       "      <td>-0.751333</td>\n",
       "      <td>-0.615479</td>\n",
       "      <td>-0.774459</td>\n",
       "      <td>0.817685</td>\n",
       "      <td>1.344045</td>\n",
       "      <td>0.490856</td>\n",
       "      <td>0.643572</td>\n",
       "      <td>-1.366485</td>\n",
       "      <td>1.052982</td>\n",
       "      <td>0.755563</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.642248</td>\n",
       "      <td>-0.590999</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>1.085998</td>\n",
       "      <td>0.402556</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>-0.463104</td>\n",
       "      <td>1.657594</td>\n",
       "      <td>0.099996</td>\n",
       "      <td>1.220423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920190113</th>\n",
       "      <td>0.663056</td>\n",
       "      <td>1.437725</td>\n",
       "      <td>-1.110954</td>\n",
       "      <td>0.309514</td>\n",
       "      <td>-1.054076</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>-0.728029</td>\n",
       "      <td>1.393851</td>\n",
       "      <td>1.159602</td>\n",
       "      <td>-1.543969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>-1.011022</td>\n",
       "      <td>-0.575822</td>\n",
       "      <td>0.730162</td>\n",
       "      <td>-0.843872</td>\n",
       "      <td>-1.535553</td>\n",
       "      <td>-1.454355</td>\n",
       "      <td>-0.509752</td>\n",
       "      <td>-0.044040</td>\n",
       "      <td>-1.091046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930010501</th>\n",
       "      <td>-0.592533</td>\n",
       "      <td>1.817990</td>\n",
       "      <td>-0.921036</td>\n",
       "      <td>-0.873506</td>\n",
       "      <td>-0.964541</td>\n",
       "      <td>-1.615351</td>\n",
       "      <td>-0.919549</td>\n",
       "      <td>1.814635</td>\n",
       "      <td>1.499758</td>\n",
       "      <td>-1.614815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606562</td>\n",
       "      <td>-0.173824</td>\n",
       "      <td>0.138459</td>\n",
       "      <td>0.460980</td>\n",
       "      <td>-0.797815</td>\n",
       "      <td>-1.443073</td>\n",
       "      <td>-0.162968</td>\n",
       "      <td>-0.022675</td>\n",
       "      <td>0.516509</td>\n",
       "      <td>-0.519815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2841 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5   \\\n",
       "code_iris                                                               \n",
       "920440109  0.155640  0.541241 -1.552484  0.356977 -1.736598  0.142796   \n",
       "930270105  1.347954  0.650689  0.018240  0.584189 -0.199877 -0.448162   \n",
       "751197316 -0.698959  0.896405 -0.875261  0.391883 -1.496848 -0.138475   \n",
       "751176716 -0.209782 -0.157673 -0.647407  0.808782 -1.313741  1.138889   \n",
       "920020104 -0.005342 -0.128149 -0.995483  0.154544  2.689951  0.246803   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "920070111  1.210889  0.605233 -1.254536  0.798792  0.989185 -0.442684   \n",
       "930050101 -1.607422  0.560672  0.211732 -0.428983  0.278820 -0.859638   \n",
       "910270114 -0.751333 -0.615479 -0.774459  0.817685  1.344045  0.490856   \n",
       "920190113  0.663056  1.437725 -1.110954  0.309514 -1.054076 -1.031078   \n",
       "930010501 -0.592533  1.817990 -0.921036 -0.873506 -0.964541 -1.615351   \n",
       "\n",
       "                 6         7         8         9   ...        54        55  \\\n",
       "code_iris                                          ...                       \n",
       "920440109 -1.446629  1.474845  1.793473 -2.367339  ... -0.648237 -0.885627   \n",
       "930270105  0.299191 -0.175236 -0.107955 -1.175052  ...  1.211076 -0.181422   \n",
       "751197316 -1.719965  2.227425  1.232168 -2.249786  ... -0.267723 -0.522346   \n",
       "751176716 -1.547369  1.824086 -0.395828 -1.862130  ...  0.210744 -0.098627   \n",
       "920020104  1.487742 -0.738581 -1.134661  1.549973  ... -0.820444 -1.813761   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "920070111  0.615255 -0.004198  0.460976  0.040388  ... -0.575556 -1.725776   \n",
       "930050101 -0.237076 -0.339976  1.102264 -0.078230  ... -0.385881  0.997247   \n",
       "910270114  0.643572 -1.366485  1.052982  0.755563  ... -1.642248 -0.590999   \n",
       "920190113 -0.728029  1.393851  1.159602 -1.543969  ...  0.632038 -1.011022   \n",
       "930010501 -0.919549  1.814635  1.499758 -1.614815  ...  0.606562 -0.173824   \n",
       "\n",
       "                 56        57        58        59        60        61  \\\n",
       "code_iris                                                               \n",
       "920440109 -0.937770  0.419687  0.025002 -1.014766 -1.895285 -0.646993   \n",
       "930270105 -0.476251  0.415405 -1.052445 -0.799308 -1.164737 -0.697996   \n",
       "751197316 -0.962249 -0.219073  0.724396 -0.248601 -1.354952 -0.742301   \n",
       "751176716 -1.785979 -0.718676  1.533811  1.153300 -1.099394 -1.633024   \n",
       "920020104  0.059071  1.641847 -0.746659 -0.228584 -0.840271  0.899284   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "920070111  0.078569  1.030678 -1.569415 -1.628996 -1.663372  0.147831   \n",
       "930050101  0.881965 -0.366797  0.009761  0.139275  1.037128  1.401160   \n",
       "910270114  0.291287  1.085998  0.402556  0.020732 -0.463104  1.657594   \n",
       "920190113 -0.575822  0.730162 -0.843872 -1.535553 -1.454355 -0.509752   \n",
       "930010501  0.138459  0.460980 -0.797815 -1.443073 -0.162968 -0.022675   \n",
       "\n",
       "                 62        63  \n",
       "code_iris                      \n",
       "920440109 -1.090850 -0.565864  \n",
       "930270105  0.541870 -1.378236  \n",
       "751197316 -1.021840 -0.666556  \n",
       "751176716 -1.415450 -0.753298  \n",
       "920020104  0.710280  0.633954  \n",
       "...             ...       ...  \n",
       "920070111  1.101275 -0.090091  \n",
       "930050101  0.522745  0.776658  \n",
       "910270114  0.099996  1.220423  \n",
       "920190113 -0.044040 -1.091046  \n",
       "930010501  0.516509 -0.519815  \n",
       "\n",
       "[2841 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_embs_dict = pd.read_pickle('embeddings/Paris/RegionDCL_20.pkl')\n",
    "region_embeddings = pd.DataFrame(region_embs_dict.values(), index=region_embs_dict.keys())\n",
    "display(region_embeddings)\n",
    "\n",
    "IRIS_Paris_embeddings = pd.read_parquet('IRIS Paris.parquet')\n",
    "IRIS_Paris_embeddings[region_embeddings.columns] = region_embeddings[:]\n",
    "del IRIS_Paris_embeddings['code_commune'], IRIS_Paris_embeddings['geometry']\n",
    "IRIS_Paris_embeddings.set_index('code_iris', inplace = True)\n",
    "\n",
    "display(IRIS_Paris_embeddings)\n",
    "IRIS_Paris_embeddings.to_parquet('RegionDCL_IRIS_Paris_embeddings.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
